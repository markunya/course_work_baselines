exp:
    project_name: finally
    exp_dir: experiment
    device: cuda
    seed: 1234
    use_wandb: true
    log_batch_size: 15
    
mel:
    segment_size: 8192
    num_mels: 80
    n_fft: 1024
    hop_size: 256
    win_size: 1024
    in_sr: 16000
    out_sr: 16000
    fmin: 0
    fmax: 8000
    fmax_for_loss: null

data:
    dataset: augmented_libritts-r
    dataset_args:
        augs_conf:
          - name: noise
            args:
              root: "../datasets_fullband/noise_fullband"
              noise_files_path:
                train: "datasets/splits/DNS_noise_split/train_files.txt"
                val: "datasets/splits/DNS_noise_split/val_files.txt"

          - name: impulse_response
            args:
              root: "../datasets_fullband/micro_irs"
              ir_files_path:
                train: "datasets/splits/micro_ir_split/train_files.txt"
                val: "datasets/splits/micro_ir_split/val_files.txt"

          - name: impulse_response
            args:
              root: "../datasets_fullband/room_irs"
              ir_files_path:
                train: "datasets/splits/DNS_ir_split/train_files.txt"
                val: "datasets/splits/DNS_ir_split/val_files.txt"
              prob: 0.8

          - name: acrusher
            args:
              prob: 0.25

          - name: crystalizer
            args:
              prob: 0.4

          - name: vibrato
            args:
              prob: 0.15

          - name: flanger
            args:
              prob: 0.15

          - name: codec
            args:
              prob: 0.45

    trainval_data_root: "../LibriTTS_R"
    train_data_file_path: "datasets/splits/LibriTTS-R_split/train_files.txt"
    val_data_file_path: "datasets/splits/LibriTTS-R_split/val_files.txt"
    inference_data_root: "../LibriTTS_R"
    inference_data_file_path: "datasets/splits/LibriTTS-R_split/test_files.txt"
    train_batch_size: 32
    workers: 16

train:
    trainer: finally_stage2_trainer
    val_metrics: ["wb_pesq", "stoi", "si_sdr", "wv-mos", "utmos", dnsmos]
    start_step: 1
    steps: 30000
    log_step: 250
    checkpoint_step: 10000
    val_step: 5000

inference:
    trainer: finally_stage2_trainer
    metrics: ["wb_pesq", "stoi", "si_sdr"]

models:
    finally_gen:
        optimizer:
          name: adamW
          args:
              lr: 0.0002
              beta1: 0.8
              beta2: 0.99

        scheduler:
            name: exponential
            args:
                gamma: 0.995
                reduce_time: "period"
                step_period: 200
                warmup_steps: 10

        checkpoint_path: "../usefull_checkpoints/finally_gen_checkpoint_100000_stage1_wavlm0.pth"
        load_optimizer_from_checkpoint: false
        
        args: {}
        losses:
            lmos:
              coef: 1.0
            gen_loss:
              coef: 0.4
            feature_loss:
              coef: 20.0
    
    ms-stft_disc:
      optimizer:
          name: adamW
          args:
              lr: 0.0002111
              beta1: 0.5
              beta2: 0.999

      scheduler:
          name: exponential
          args:
              gamma: 0.995
              reduce_time: "period"
              step_period: 200

      checkpoint_path: null
      args:
          filters: 32
          n_ffts: [2048, 1024, 512, 256, 128]
          hop_lengths: [512, 256, 128, 64, 32]
          win_lengths: [2048, 1024, 512, 256, 128]
      losses:
          disc_loss:
            coef: 1.0
    